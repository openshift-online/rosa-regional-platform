#!/usr/bin/env -S uv run
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "PyYAML>=6.0",
# ]
# ///
"""
Generic Values Renderer

This script renders configuration values by:
1. Reading config.yaml to get the list of shards and their configurations
2. For each shard and cluster type, loading defaults from existing values files
3. Merging shard-specific overrides with defaults
4. Outputting merged values files to rendered/{environment}/{region}/{clustertype}-values.yaml

The script is completely transparent and does no magic - it simply merges YAML values.
"""

import sys
from pathlib import Path
from typing import Any, Dict, List

import yaml


def load_yaml(file_path: Path) -> Dict[str, Any]:
    """Load and parse a YAML file.

    Args:
        file_path: Path to the YAML file

    Returns:
        Parsed YAML content as a dictionary
    """
    if not file_path.exists():
        return {}

    with open(file_path, 'r') as f:
        return yaml.safe_load(f) or {}


def validate_shard_uniqueness(shards):
    """Ensure environment + region combinations are unique across shards.

    Args:
        shards: List of shard configurations

    Raises:
        ValueError: If duplicate environment + region combinations are found
    """
    seen_combinations = set()
    for shard in shards:
        combination = (shard.get('environment'), shard.get('region'))
        if combination in seen_combinations:
            raise ValueError(f"Duplicate environment + region combination: {combination}")
        seen_combinations.add(combination)


def validate_config_revisions(shards):
    """Validate that specified config revisions are valid git commit hashes.

    Args:
        shards: List of shard configurations

    Raises:
        ValueError: If a specified config revision is not a valid git commit hash format
    """
    import re

    # Git commit hash pattern (7-40 hex characters)
    commit_hash_pattern = re.compile(r'^[a-f0-9]{7,40}$')

    for shard in shards:
        region = shard.get('region', 'unknown')
        environment = shard.get('environment', 'unknown')
        config_revisions = shard.get('config_revision', {})

        for cluster_type, revision in config_revisions.items():
            if revision:  # Only validate if revision is specified
                if not commit_hash_pattern.match(revision):
                    raise ValueError(
                        f"Invalid commit hash for shard {region} ({environment}): "
                        f"'{revision}' (cluster_type: {cluster_type}). "
                        f"Expected 7-40 character hexadecimal string."
                    )


def save_yaml(data: Dict[str, Any], file_path: Path, cluster_type: str, shard: Dict[str, Any]) -> None:
    """Save a dictionary as a YAML file with proper headers.

    Args:
        data: Dictionary to save
        file_path: Path where to save the YAML file
        cluster_type: Type of cluster (management-cluster, regional-cluster, etc.)
        shard: Shard configuration
    """
    file_path.parent.mkdir(parents=True, exist_ok=True)

    # Generate header
    region = shard['region']
    environment = shard['environment']

    header = f"""# GENERATED FILE - DO NOT EDIT MANUALLY
#
# This file is automatically generated by the render script.
# To make changes:
# - For default changes: Edit values.yaml files in argocd/config/{cluster_type}/*/values.yaml or argocd/config/shared/*/values.yaml
# - For shard-specific changes: Edit argocd/config.yaml
# - Then run: argocd/scripts/render.py
#
# Cluster Type: {cluster_type}
# Shard: {region} ({environment})
# Generated: {Path(__file__).name}
#

"""

    with open(file_path, 'w') as f:
        f.write(header)
        yaml.dump(data, f, default_flow_style=False, sort_keys=False, allow_unicode=True, width=float('inf'))


def deep_merge(base: Dict[str, Any], overlay: Dict[str, Any]) -> Dict[str, Any]:
    """Recursively merge two dictionaries.

    Args:
        base: Base dictionary
        overlay: Dictionary to merge into base

    Returns:
        Merged dictionary
    """
    result = base.copy()

    for key, value in overlay.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value

    return result


def get_cluster_types(base_dir: Path) -> List[str]:
    """Discover cluster types by looking at directories.

    Args:
        base_dir: Base directory to scan

    Returns:
        List of cluster type names
    """
    cluster_types = []
    for item in base_dir.iterdir():
        if item.is_dir() and not item.name.startswith('.') and item.name.endswith('cluster'):
            cluster_types.append(item.name)
    return cluster_types


def create_applicationset_template(cluster_type: str, environment: str, region: str, config_revision: str = None, base_dir: Path = None) -> Dict[str, Any]:
    """Create ApplicationSet YAML template with specific commit hash or default revision.

    Args:
        cluster_type: Type of cluster (management-cluster, regional-cluster, etc.)
        environment: Environment name
        region: AWS region
        config_revision: Optional commit hash for versioned deployments
        base_dir: Base directory path (for loading base ApplicationSet)

    Returns:
        ApplicationSet dictionary
    """
    # Always load the base ApplicationSet as the starting point
    base_applicationset_path = base_dir / 'applicationset' / 'base-applicationset.yaml'
    if not base_applicationset_path.exists():
        raise ValueError(f"Base ApplicationSet not found: {base_applicationset_path}")

    applicationset = load_yaml(base_applicationset_path)

    # If config_revision is specified, override the git revision to use the specific commit hash
    if config_revision:
        # Find the git generator in the matrix and update its revision
        generators = applicationset['spec']['generators'][0]['matrix']['generators']
        for generator in generators:
            if 'git' in generator:
                # Override revision with specific commit hash
                generator['git']['revision'] = config_revision
                break

        # Update only the first source (chart + values.yaml) to use the specific commit hash
        # The second source (ref: values) should keep using metadata.annotations.git_revision
        sources = applicationset['spec']['template']['spec']['sources']
        for i, source in enumerate(sources):
            if 'targetRevision' in source and 'ref' not in source:
                # This is the chart source (first source) - update to use config_revision
                source['targetRevision'] = config_revision

    return applicationset


def render_shard_applicationsets(
    shard: Dict[str, Any],
    cluster_types: List[str],
    rendered_dir: Path,
    base_dir: Path
) -> None:
    """Generate ApplicationSet files for each cluster type.

    Args:
        shard: Shard configuration
        cluster_types: List of cluster types to render
        rendered_dir: Path to the rendered output directory
        base_dir: Base directory path (for loading base ApplicationSet)
    """
    environment = shard['environment']
    region = shard['region']
    config_revisions = shard.get('config_revision', {})

    # Create output directory
    output_dir = rendered_dir / environment / region
    output_dir.mkdir(parents=True, exist_ok=True)

    # Process each cluster type
    for cluster_type in cluster_types:
        config_revision = config_revisions.get(cluster_type)  # Get cluster-specific commit hash (may be None)

        applicationset_data = create_applicationset_template(cluster_type, environment, region, config_revision, base_dir)

        # Create cluster-type manifests directory (simplified structure)
        manifests_dir = output_dir / f'{cluster_type}-manifests'
        manifests_dir.mkdir(parents=True, exist_ok=True)

        # ApplicationSet goes in the manifests directory
        output_file = manifests_dir / 'applicationset.yaml'
        revision_info = config_revision[:8] if config_revision else "metadata.annotations.git_revision"

        with open(output_file, 'w') as f:
            f.write(f"""# GENERATED FILE - DO NOT EDIT MANUALLY
#
# This file is automatically generated by the render script.
# To make changes:
# - Edit argocd/config.yaml for config_revision references
# - Then run: argocd/scripts/render.py
#
# Cluster Type: {cluster_type}
# Shard: {region} ({environment})
# Config Revision: {revision_info}
# Generated: {Path(__file__).name}
#

""")
            yaml.dump(applicationset_data, f, default_flow_style=False, sort_keys=False, allow_unicode=True, width=float('inf'))

        print(f"  [OK] {output_file.relative_to(rendered_dir.parent)} (Config Revision: {revision_info})")


def render_shard_values(
    shard: Dict[str, Any],
    cluster_types: List[str],
    base_dir: Path,
    rendered_dir: Path
) -> None:
    """Render values files for all cluster types for a shard.

    Args:
        shard: Shard configuration
        cluster_types: List of cluster types to render
        base_dir: Base directory containing cluster type directories
        rendered_dir: Path to the rendered output directory
    """
    environment = shard['environment']
    region = shard['region']

    print(f"Processing shard: {region} ({environment})")

    # Create output directory
    output_dir = rendered_dir / environment / region
    output_dir.mkdir(parents=True, exist_ok=True)

    # Process each cluster type
    for cluster_type in cluster_types:
        # Get shard-specific values for this cluster type
        shard_cluster_values = shard.get('values', {}).get(cluster_type, {})

        # Get top-level values from the shard (not cluster-specific)
        shard_top_level_values = {k: v for k, v in shard.get('values', {}).items()
                                 if k not in cluster_types and k != 'global'}

        # Get global values that apply to this cluster type
        global_values = shard.get('values', {}).get('global', {})

        # Merge only the overrides: global_values <- shard_top_level <- shard_cluster_values
        # Do NOT include helm chart defaults - those stay in the charts
        override_values = deep_merge(global_values.copy(), shard_top_level_values)
        override_values = deep_merge(override_values, shard_cluster_values)

        # Always save values file (even if empty) as it's referenced in ApplicationSet
        output_file = output_dir / f'{cluster_type}-values.yaml'
        save_yaml(override_values, output_file, cluster_type, shard)
        if override_values:
            print(f"  [OK] {output_file.relative_to(rendered_dir.parent)}")
        else:
            print(f"  [OK] {output_file.relative_to(rendered_dir.parent)} (empty - no overrides)")


def main() -> int:
    """Main entry point for the script.

    Returns:
        Exit code (0 for success, 1 for error)
    """
    # Determine script location and project root
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent

    config_file = project_root / 'argocd' / 'config.yaml'
    base_dir = project_root / 'argocd' / 'config'
    rendered_dir = project_root / 'argocd' / 'rendered'

    if not config_file.exists():
        print(f"Error: Config file not found: {config_file}", file=sys.stderr)
        return 1

    # Load config
    config = load_yaml(config_file)

    # Get shards from config
    shards = config.get('shards', [])
    if not shards:
        print("Error: No shards found in config.yaml", file=sys.stderr)
        return 1

    # Validate environment + region uniqueness
    try:
        validate_shard_uniqueness(shards)
    except ValueError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1

    # Validate config revision references
    try:
        validate_config_revisions(shards)
    except ValueError as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1

    # Discover cluster types
    cluster_types = get_cluster_types(base_dir)
    if not cluster_types:
        print("Error: No cluster types found", file=sys.stderr)
        return 1

    print(f"Found {len(shards)} shard(s)")
    print(f"Found cluster types: {', '.join(cluster_types)}")
    print()

    # Process each shard
    for shard in shards:
        environment = shard.get('environment')
        region = shard.get('region')

        if not (environment and region):
            print(f"Error: config.yaml entry does not require environment and region: {shard}", file=sys.stderr)
            return 0

        render_shard_values(shard, cluster_types, base_dir, rendered_dir)
        render_shard_applicationsets(shard, cluster_types, rendered_dir, base_dir)
        print()

    print("[OK] Rendering complete")
    return 0


if __name__ == '__main__':
    sys.exit(main())